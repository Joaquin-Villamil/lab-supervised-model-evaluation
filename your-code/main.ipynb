{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning Model Evaluation Lab\n",
    "\n",
    "Complete the exercises below to solidify your knowledge and understanding of supervised learning model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "\n",
    "data = load_boston()\n",
    "\n",
    "X = pd.DataFrame(data[\"data\"], columns=data[\"feature_names\"])\n",
    "y = pd.DataFrame(data[\"target\"], columns=['MEDV'])\n",
    "\n",
    "data = pd.concat([X, y], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Split this data set into training (80%) and testing (20%) sets.\n",
    "\n",
    "The `MEDV` field represents the median value of owner-occupied homes (in $1000's) and is the target variable that we will want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train,y_test = train_test_split(X,y, test_size=0.2,random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train a `LinearRegression` model on this data set and generate predictions on both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg=LinearRegression()\n",
    "linreg.fit(X_train,y_train)\n",
    "\n",
    "y_pred_train = linreg.predict(X_train)\n",
    "y_pred_test = linreg.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Calculate and print R-squared for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valor R2: (0.7508856358979673, 0.668759493535634)\n"
     ]
    }
   ],
   "source": [
    "train_score = linreg.score(X_train,y_train)\n",
    "test_score=linreg.score(X_test,y_test)\n",
    "\n",
    "# print(linreg.coef_)\n",
    "print(f'Valor R2: {train_score,test_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Calculate and print mean squared error for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valor mean squared error: (21.641412753226312, 24.291119474973375)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "predicted = linreg.predict(X_test)\n",
    "\n",
    "print(f'Valor mean squared error: {mean_squared_error(y_train,y_pred_train),mean_squared_error(y_test,y_pred_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Calculate and print mean absolute error for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valor mean squared error: (3.3147716267832195, 3.1890919658878145)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "# predicted = linreg.predict(X_test)\n",
    "mean_absolute_error(y_train,y_pred_train)\n",
    "mean_absolute_error(y_test,y_pred_test)\n",
    "print(f'Valor mean squared error: {mean_absolute_error(y_train,y_pred_train),mean_absolute_error(y_test,y_pred_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "data = load_iris()\n",
    "\n",
    "X = pd.DataFrame(data[\"data\"], columns=data[\"feature_names\"])\n",
    "y = pd.DataFrame(data[\"target\"], columns=[\"class\"])\n",
    "\n",
    "data = pd.concat([X, y], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Split this data set into training (80%) and testing (20%) sets.\n",
    "\n",
    "The `class` field represents the type of flower and is the target variable that we will want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train,y_test = train_test_split(X,y, test_size=0.2,random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train a `LogisticRegression` model on this data set and generate predictions on both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.discriminant_analysis import  LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "modelos=[]\n",
    "modelos.append(('LR',LogisticRegression()))\n",
    "modelos.append(('LDA',LinearDiscriminantAnalysis()))\n",
    "modelos.append(('KNN',KNeighborsClassifier()))\n",
    "modelos.append(('CART',DecisionTreeClassifier()))\n",
    "modelos.append(('NB',GaussianNB()))\n",
    "modelos.append(('SVM',SVC()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR,1.0,0.9583333333333334\n",
      "LDA,1.0,0.975\n",
      "KN3,1.0,0.95\n",
      "KNN5,1.0,0.9666666666666667\n",
      "CART,1.0,1.0\n",
      "NB,1.0,0.95\n",
      "SVM,1.0,0.9916666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  del sys.path[0]\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  del sys.path[0]\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "modelos=[]\n",
    "\n",
    "modelos.append(('LR',LogisticRegression()))\n",
    "modelos.append(('LDA',LinearDiscriminantAnalysis()))\n",
    "modelos.append(('KN3',KNeighborsClassifier(n_neighbors=3)))\n",
    "modelos.append(('KNN5',KNeighborsClassifier(n_neighbors=5)))\n",
    "modelos.append(('CART',DecisionTreeClassifier()))\n",
    "modelos.append(('NB',GaussianNB()))\n",
    "modelos.append(('SVM',SVC()))\n",
    "\n",
    "\n",
    "for nombre, modelo in modelos:\n",
    "    fit = modelo.fit(X_train,y_train)\n",
    "    y_pred_test=fit.predict(X_test)\n",
    "    y_pred_train=fit.predict(X_train)\n",
    "\n",
    "    score_test = accuracy_score(y_test,y_pred_test)\n",
    "    score_train = accuracy_score(y_train,y_pred_train)\n",
    "\n",
    "    print(f'{nombre},{score_test},{score_train}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Calculate and print the accuracy score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 1.0\n",
      "Accuracy 0.9916666666666667\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy {accuracy_score(y_test, y_pred_test)}')\n",
    "print(f'Accuracy {accuracy_score(y_train, y_pred_train)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Calculate and print the balanced accuracy score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 1.0\n",
      "Accuracy 0.991869918699187\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "print(f'Accuracy {balanced_accuracy_score(y_test, y_pred_test)}')\n",
    "print(f'Accuracy {balanced_accuracy_score(y_train, y_pred_train)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Calculate and print the precision score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 1.0\n",
      "Accuracy 0.9916666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "pre_sc_test = precision_score(y_test, y_pred_test,average='macro')\n",
    "pre_sc_train = precision_score(y_train, y_pred_train,average='macro')\n",
    "print(f'Accuracy {pre_sc_test}')\n",
    "print(f'Accuracy {pre_sc_train}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Calculate and print the recall score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########################################\n",
      "\n",
      "Classifier performance on training dataset\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class-0       1.00      1.00      1.00        40\n",
      "     Class-1       1.00      0.98      0.99        41\n",
      "     Class-2       0.97      1.00      0.99        39\n",
      "\n",
      "    accuracy                           0.99       120\n",
      "   macro avg       0.99      0.99      0.99       120\n",
      "weighted avg       0.99      0.99      0.99       120\n",
      "\n",
      "########################################\n",
      "\n",
      "########################################\n",
      "\n",
      "Classifier performance on test dataset\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class-0       1.00      1.00      1.00        10\n",
      "     Class-1       1.00      1.00      1.00         9\n",
      "     Class-2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "########################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_names = ['Class-0', 'Class-1','Class-2']\n",
    "print(\"\\n\" + \"#\"*40)\n",
    "print(\"\\nClassifier performance on training dataset\\n\")\n",
    "print(classification_report(y_train, y_pred_train, target_names=class_names))\n",
    "print(\"#\"*40 + \"\\n\")\n",
    "print(\"#\"*40)\n",
    "print(\"\\nClassifier performance on test dataset\\n\")\n",
    "print(classification_report(y_test, y_pred_test, target_names=class_names))\n",
    "print(\"#\"*40 + \"\\n\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Calculate and print the F1 score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########################################\n",
      "\n",
      "Classifier performance on training dataset\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class-0       1.00      1.00      1.00        40\n",
      "     Class-1       1.00      0.98      0.99        41\n",
      "     Class-2       0.97      1.00      0.99        39\n",
      "\n",
      "    accuracy                           0.99       120\n",
      "   macro avg       0.99      0.99      0.99       120\n",
      "weighted avg       0.99      0.99      0.99       120\n",
      "\n",
      "########################################\n",
      "\n",
      "########################################\n",
      "\n",
      "Classifier performance on test dataset\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class-0       1.00      1.00      1.00        10\n",
      "     Class-1       1.00      1.00      1.00         9\n",
      "     Class-2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "########################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_names = ['Class-0', 'Class-1','Class-2']\n",
    "print(\"\\n\" + \"#\"*40)\n",
    "print(\"\\nClassifier performance on training dataset\\n\")\n",
    "print(classification_report(y_train, y_pred_train, target_names=class_names))\n",
    "print(\"#\"*40 + \"\\n\")\n",
    "print(\"#\"*40)\n",
    "print(\"\\nClassifier performance on test dataset\\n\")\n",
    "print(classification_report(y_test, y_pred_test, target_names=class_names))\n",
    "print(\"#\"*40 + \"\\n\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Generate confusion matrices for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10,  0,  0],\n",
       "       [ 0,  9,  0],\n",
       "       [ 0,  0, 11]], dtype=int64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test,y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[40,  0,  0],\n",
       "       [ 0, 40,  1],\n",
       "       [ 0,  0, 39]], dtype=int64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train,y_pred_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: For each of the data sets in this lab, try training with some of the other models you have learned about, recalculate the evaluation metrics, and compare to determine which models perform best on each data set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
